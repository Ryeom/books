```ad-summary
이 장은 $\text{CPU}$의 성능과 프로그래밍 편의성을 극대화하기 위해 도입된 컴퓨터 아키텍처의 복잡한 구조 개선 사항을 설명한다. 핵심은 함수 호출과 재귀를 지원하는 스택의 원리, 멀티태스킹 환경에서 프로그램 간 격리를 담당하는 메모리 관리 장치($\text{MMU}$) 및 가상 메모리 시스템, 그리고 성능을 최적화하는 메모리 계층 구조에 대한 이해이다.

```


### 1. 아키텍처의 기본 구조와 성능 진화

컴퓨터 구조는 명령어와 데이터 메모리를 분리하여 속도를 높인 하버드 구조와, 명령어와 데이터가 메모리를 공유하는 폰 노이만 구조로 나뉜다. 반도체 회로가 작아지면서 전력 장벽 문제에 부딪히자, $\text{CPU}$는 프로세서 코어의 정의를 바꾸고 멀티코어 시스템으로 진화한다. 또한, 메모리와 $\text{I/O}$를 $\text{CPU}$와 같은 칩에 패키징하는 방식에 따라 마이크로프로세서와 마이크로컴퓨터($\text{SoC}$) 등으로 구분된다.

### 2. 프로그램 제어 및 스택 구조

프로그래밍 효율을 위해 코드를 재사용하는 함수(서브루틴) 개념이 필수적이며, 함수 호출 후 원래 자리로 돌아오는 반환 주소를 기억하는 메커니즘이 필요하다. 특히 재귀 함수처럼 여러 호출 위치를 순서대로 저장하고 복원하기 위해 스택(stack) 구조가 도입된다. 스택은 $\text{LIFO}$ 방식으로 작동하며, 함수 호출 시 반환 주소와 지역 변수를 포함하는 스택 프레임을 저장한다. 스택의 범위를 제한하는 한계 레지스터는 스택 오버플로를 방지하는 역할을 한다.


### 3. 운영체제와 프로그램 격리 (MMU)

프로그램이 동시에 실행되는 멀티태스킹 환경을 관리하기 위해 운영체제($\text{OS}$)가 등장한다. $\text{OS}$는 인터럽트 시스템을 통해 외부 이벤트(타이머, $\text{I/O}$)에 즉각적으로 반응하여 실행 중인 프로그램을 중단(중단)시키고 인터럽트 핸들러를 실행한다. 프로그램 간의 메모리 간섭 및 $\text{OS}$ 보호를 위해 \*\*메모리 관리 장치($\text{MMU}$)가 도입된다. $\text{MMU}$는 가상 주소를 물리 주소로 변환하여 각 프로그램에게 자신만의 메모리 공간이 있는 것처럼 보이게 한다(가상 메모리). 물리적 메모리가 부족하면 $\text{OS}$는 사용 빈도가 낮은 페이지를 디스크로 옮기는 스와핑을 통해 가용 메모리를 확장한다.


### 4. 성능 최적화와 계층 구조

$\text{CPU}$와 주 메모리 사이의 속도 격차를 해소하기 위해 메모리 계층 구조가 도입된다. 이 구조는 빠르고 비싸지만 용량이 작은 레지스터와 \*\*캐시($\text{L1/L2/L3}$)를 $\text{CPU}$ 가까이에 배치하고, 느리고 저렴한 주 메모리 및 대량 저장장치로 이어진다. $\text{CPU}$는 캐시에서 데이터를 찾지 못하는 캐시 실패를 줄이기 위해 분기 예측 및 순서를 벗어나는 실행 기술을 사용한다. 또한, $\text{CPU}$의 부하를 줄이기 위해 데이터 복사를 전담하는 코프로세서나 $\text{DMA}$ 같은 기술이 사용된다.


---

# 키워드 정리
### 1. 컴퓨터 구조의 분류와 진화

- 폰 노이만 구조 (von Neumann Architecture)
    - 등장 배경: 초기 컴퓨터 시스템을 효율적으로 조직화하기 위해 명령어와 데이터를 메모리에 저장하는 방식에 대한 설계 표준이 필요했다.
    - 필요성/중요성: 명령어와 데이터가 동일한 메모리와 버스를 공유하는 구조이며, 현대 대부분의 컴퓨터가 이 구조를 기반으로 한다.
    - 본문 정의: 명령어와 데이터가 같은 메모리 배열을 공유하는 구조이며, 하나의 주소 버스와 데이터 버스를 사용한다.
    - 흐름 연결고리: 직전 키워드 없음 $\to$ 직후 - 폰 노이만 구조가 버스를 공유하여 발생하는 성능 병목 현상(bottleneck)을 해결하기 위한 대안인 하버드 구조와 비교된다.
    - 잠재적 혼동 개념: 하버드 구조와 혼동하지 않아야 한다. 하버드 구조는 명령어와 데이터를 위한 메모리와 버스가 분리되어 동시에 접근할 수 있어 더 빠르다.

- 전력 장벽 (Power wall)
    - 등장 배경: 반도체 회로 크기는 줄었으나, CPU 속도가 빨라지면서 전력 소모가 증가하고 단위 면적당 열 발생이 심화되어 회로의 녹는점 이상으로 온도가 올라가는 문제를 해결해야 했다.
    - 필요성/중요성: 2000년경 프로세서 설계가 직면한 근본적인 한계로, 이 장벽 때문에 CPU는 속도 경쟁 대신 멀티코어 및 저전력 구조로의 진화를 선택했다.
    - 본문 정의: 열로 인해 회로를 이루는 물질의 녹는점 이상으로 온도가 올라가는 것을 방지하면서 회로를 소형화 고성능화하기가 어려워진 한계를 뜻한다.
    - 흐름 연결고리: 직전 - 폰 노이만/하버드 구조 $\to$ 직후 - 전력 장벽을 극복하기 위한 해결책으로 프로세서 코어가 다수 들어가는 멀티코어 시스템이 일반화되었다.

- 마이크로프로세서 / 마이크로컴퓨터 (SoC)
    - 등장 배경: 물리적인 패키징 방식에 따라 CPU의 역할과 시스템 구성이 달라지기 때문에 용어 구분이 필요했다.
    - 필요성/중요성: 마이크로프로세서는 $\text{CPU}$ 코어만 패키징하여 큰 시스템에 쓰이고, 마이크로컴퓨터($\text{SoC}$)는 $\text{CPU}$와 메모리, $\text{I/O}$를 하나의 칩에 통합하여 식기세척기나 핸드폰 같은 임베디드 장치에 쓰인다.
    - 본문 정의: 마이크로프로세서는 메모리와 $\text{I/O}$가 $\text{CPU}$와 다른 패키지에 있는 프로세서이며, 마이크로컴퓨터는 모든 요소를 한 칩 안에 패키징한 작은 컴퓨터이다. $\text{SoC}$는 더 복잡한 마이크로컴퓨터를 뜻한다.
    - 흐름 연결고리: 직전 - 멀티코어 시스템으로의 진화 $\to$ 직후 - 프로그래밍 편의성을 위해 코드를 재사용하는 함수와 그 실행 메커니즘인 스택의 문제로 논의가 전환된다.

### 2. 프로그램 실행 구조와 메모리 관리 기초

- 스택(Stack) / LIFO
    - 등장 배경: 함수 호출 시 돌아올 위치(반환 주소)나 지역 변수 등 데이터를 여러 개 저장해야 하는 재귀 함수가 등장하면서, 저장과 복구가 순서대로 이루어지는 구조가 필요했다.
    - 필요성/중요성: 함수 호출의 반환 주소와 지역 변수를 저장하는 스택 프레임을 관리하며, $\text{LIFO}$ 방식으로 작동하여 함수 호출이 끝날 때마다 데이터가 정확히 제거되는 것을 보장한다.
    - 본문 정의: 물건을 쌓아 올린다는 뜻으로, '나중에 들어온 것이 먼저 나간다($\text{LIFO, last in, first out}$)'는 구조이다.
    - 흐름 연결고리: 직전 - 함수 호출과 재귀의 필요성 $\to$ 직후 - 스택 영역의 안전성을 확보하고 오류를 처리하는 예외 및 인터럽트 메커니즘으로 이어진다.

- 인터럽트 시스템 (Interrupt System) / 폴링 (Polling)
    - 등장 배경: $\text{CPU}$가 $\text{I/O}$ 장치의 준비 상태를 계속 검사하는 폴링 방식이 비효율적이고 중요한 외부 이벤트를 놓칠 수 있어, 프로그램 실행을 잠시 중단시키는 하드웨어 메커니즘이 필요했다.
    - 필요성/중요성: $\text{CPU}$가 외부 요청(타이머, $\text{I/O}$)에 즉시 반응하여 인터럽트 핸들러를 실행하게 한다. 이는 $\text{OS}$의 멀티태스킹 제어와 $\text{CPU}$의 효율적인 자원 활용에 필수적이다.
    - 본문 정의: $\text{CPU}$ 실행을 잠깐 중단시켜 주의를 기울여야 하는 외부 요소에 대응하게 만드는 시스템이다. 폴링은 $\text{CPU}$가 문 앞에 누가 왔는지 계속 검사하는 것과 같은 방식이다.
    - 흐름 연결고리: 직전 - 스택을 이용한 반환 주소 저장 $\to$ 직후 - 인터럽트와 타이머를 이용해 여러 프로그램을 전환시키고 관리하는 $\text{OS}$와 멀티태스킹으로 이어진다.

- 메모리 관리 장치 (MMU, Memory Management Unit) / 가상 메모리 (Virtual Memory)
    - 등장 배경: 멀티태스킹 환경에서 사용자 프로그램 간 메모리 영역 침범 및 $\text{OS}$ 메모리 덮어쓰기 같은 오류를 방지하고, 물리 메모리보다 큰 메모리를 사용하는 것처럼 보이게 해야 했다.
    - 필요성/중요성: $\text{MMU}$는 프로그램의 가상 주소를 실제 물리 주소로 변환하여 프로그램 간의 완벽한 격리를 제공한다. 가상 메모리는 필요한 메모리 페이지를 디스크와 교환(스와핑)하여 물리 메모리 크기를 초과하는 공간을 제공한다.
    - 본문 정의: $\text{MMU}$는 가상 주소를 물리 주소로 변환하는 복잡한 하드웨어이며, $\text{OS}$는 이를 사용해 프로그램에게 가상 메모리를 제공한다.
    - 흐름 연결고리: 직전 - $\text{OS}$의 멀티태스킹 제어 $\to$ 직후 - $\text{MMU}$가 프로그램을 격리하는 영역인 시스템 공간과 사용자 공간의 구분이 생긴다.
    - 잠재적 혼동 개념: 페이지 폴트(Page Fault)는 프로그램이 물리 메모리에 없는 주소에 접근할 때 발생하는 예외이며, $\text{OS}$는 이를 이용해 디스크에서 메모리로 페이지를 불러오는 요구불 페이징을 수행한다.

    ### 3. 최종 아키텍처와 성능 최적화

- 메모리 계층 (Memory Hierarchy) / 캐시 (Cache)
    - 등장 배경: $\text{CPU}$의 속도가 주 메모리보다 훨씬 빨라지면서 $\text{CPU}$가 느린 메모리를 기다리며 시간을 낭비하는 문제(속도 격차)를 해결해야 했다.
    - 필요성/중요성: 빠르고 비싼 메모리를 $\text{CPU}$ 가까이에 계층적으로 배치하여 $\text{CPU}$의 대기 시간을 최소화한다. 캐시($\text{L1/L2/L3}$)는 주 메모리보다 빠르고 작은 온칩 메모리이다.
    - 본문 정의: 속도와 비용에 따라 레지스터, 캐시($\text{L1, L2, L3}$), 주 메모리, 대량 저장장치 순으로 구성된 메모리 시스템이다.
    - 흐름 연결고리: 직전 - $\text{MMU}$와 가상 메모리 $\to$ 직후 - 캐시의 효율을 높이고 $\text{CPU}$의 유휴 시간을 줄이는 성능 최적화 기술로 이어진다.
    - 잠재적 혼동 개념: 캐시 적중(Cache Hit)은 원하는 데이터가 캐시에 있는 경우이며, 캐시 실패(Cache Miss)는 캐시에 데이터가 없어 주 메모리에서 데이터를 읽어와야 하는 경우이다.

- 성능 최적화 기술 (Branch Prediction, O-O-O Execution)
    - 등장 배경: 메모리 계층으로도 해결되지 않는 $\text{CPU}$와 메모리 간의 속도 격차를 숨기고 $\text{CPU}$의 유휴 시간을 없애기 위해 필요했다.
    - 필요성/중요성: 분기 예측은 조건 분기 명령어의 결과를 미리 예측하여 데이터를 프리페치하고, 순서를 벗어나는 실행($\text{out-of-order execution}$)은 명령어 순서를 바꿔 가장 효율적으로 $\text{CPU}$를 가동시켜 성능을 극대화한다.
    - 본문 정의: 분기 예측은 조건 분기 명령어의 결과를 예측하여 캐시를 준비시키는 회로이며, 순서를 벗어나는 실행은 프로그램에 명시된 순서를 벗어나 명령어를 수행하게 해주는 회로이다.
    - 흐름 연결고리: 직전 - 메모리 계층 $\to$ 직후 - $\text{CPU}$의 부하를 줄이는 $\text{DMA}$와 코프로세서 기술로 논의가 마무리된다.