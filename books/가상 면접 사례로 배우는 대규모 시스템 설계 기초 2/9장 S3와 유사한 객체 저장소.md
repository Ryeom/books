이번 장의 설계는 아마존 S3와 유사한 100 페타바이트(PB) 규모의 분산 객체 저장소 구축을 목표로 한다. 핵심 설계 목표는 99.9999%의 데이터 내구성과 저장소 비용 효율성을 달성하는 것이다. 객체 저장소는 데이터가 불변(Immutable) 하고 읽기 연산이 압도적으로 많음을 전제로 한다.

시스템은 메타데이터 저장소와 객체 데이터 저장소를 분리하는 UNIX 파일 시스템과 유사한 2계층 구조를 채택. 데이터의 안정성과 비용 효율을 위해 다중화(Replication) 또는 소거 코드(Erasure Coding) 전략을 사용했다. 특히, 대용량 파일 처리를 위해 멀티파트 업로드를 지원하고, 효율적인 저장소 관리를 위해 작은 객체들을 모아 큰 파일로 저장하는 방식과 쓰레기 수집 메커니즘을 구현했다.



## 단계별 설계 분석

### 1. 문제 정의 및 저장소 특성 이해함

객체 저장소는 블록/파일 저장소와 달리 불변성, 최고의 확장성, 저비용에 중점을 둠. 주요 요구사항은 100 PB 데이터 수용 및 식스 나인(99.9999%) 내구성 확보이다.

|저장소 유형|특징|적합한 용도|
|---|---|---|
|블록|원시 블록 제공, 최상 성능, 유연성 높음.|DB, VM과 같은 고성능 애플리케이션.|
|파일|계층적 디렉터리 구조 제공, 범용적임.|범용 파일 시스템 접근.|
|객체|불변, 수평적 구조, RESTful API 접근, 최상 확장성.|백업, 아카이브, 구조화되지 않은 데이터 보관.|



### 2. 개략적 아키텍처 및 핵심 원리

#### 2.1. 2계층 구조 분리

설계의 핵심은 메타데이터와 객체 데이터를 분리하는 것이다.

- 메타데이터 저장소: 객체 이름, 버전 ID 등 변경 가능한 정보를 보관함. 객체 URI를 키로 객체 ID(UUID)를 조회하는 역할을 함.
- 객체 데이터 저장소: 실제 불변의 객체 데이터(바이너리)를 보관함. 객체 ID(UUID)를 통해 접근됨.

#### 2.2. 아키텍처 컴포넌트

- API 서비스: 요청 처리 및 IAM, 메타데이터, 데이터 저장소 호출을 조율하는 무상태 서비스.
- 데이터 저장소: 데이터 라우팅 서비스, 배치 서비스(합의 프로토콜 사용), 데이터 노드로 구성되어 데이터 저장/조회/다중화를 담당.



### 3. 상세 설계 및 기술적 도전 과제 해결

#### 3.1. 데이터 저장소 설계 및 효율성 확보

- 소형 객체 처리: 작은 객체들을 개별 파일로 저장하면 아이노드 한계 초과 및 디스크 낭비 문제가 발생함. 이를 해결하기 위해 WAL(Write-Ahead Log)처럼 작은 객체들을 모아 큰 파일 하나에 순차적으로 기록한다.
- 객체 소재 확인: 각 데이터 노드는 객체의 물리적 위치(`file_name`, `start_offset`, `object_size`)를 지역적인 관계형 DB(예: SQLite) 에 저장하여 객체 ID로 빠르게 조회.
- 데이터 흐름: 데이터 라우팅 서비스는 안정 해시를 사용하여 데이터를 보관할 주 데이터 노드를 결정하고, 주 노드는 부 노드에 다중화한 후 응답하여 강력한 데이터 일관성을 확보.

#### 3.2. 데이터 내구성 및 정확성 보장

- 다중화 (Replication): 데이터를 여러 가용성 구역(AZ)에 3중 복제하여 99.9999% 내구성을 달성. (응답 지연에 유리함)
- 소거 코드 (Erasure Coding): 데이터를 분할하고 패리티 정보를 추가하여 중복성을 확보. 저장소 효율성이 높고 내구성이 최상임 (99.999999999%), 그러나 쓰기/읽기 지연 시간이 증가.
- 정확성 검증: 메모리 훼손 등의 데이터 오류를 방지하기 위해 객체 데이터의 끝에 체크섬(Checksum) 을 추가. 읽기 시 체크섬을 재계산하여 데이터 무결성을 검증하고, 실패 시 다른 사본에서 복구를 시도.

#### 3.3. 메타데이터 관리 및 목록 조회 최적화

- 객체 버전: 객체 덮어쓰기 시 `object_version` (TIMEUUID)이 다른 새 레코드를 추가하여 모든 버전을 유지함. 삭제 시에는 삭제 표식(Delete Marker) 레코드를 삽입.
- 대용량 파일 처리: 수 GB 이상의 객체 업로드 성능 최적화를 위해 멀티파트 업로드를 지원. 파일을 조각으로 분할하여 독립적으로 업로드한 후, 서버에서 조립.
- 목록 조회 (List): 샤딩된 환경에서 `prefix` 기반 목록 조회와 페이지 나눔 구현은 복잡. 이를 단순화하기 위해 목록 조회용 데이터를 `bucket_id` 기준으로 별도 테이블에 비정규화하여 구현하는 방안을 고려.

#### 3.4. 저장소 회수 (Garbage Collection)

- 대상: 삭제 표식이 있는 객체, 취소된 멀티파트 업로드 조각, 훼손된 데이터 등이 쓰레기 데이터.
- 정리 메커니즘: 쓰레기 수집기는 주기적으로 정리(Compaction) 를 수행함. 유효한 객체들만 새 파일로 복사하고, 삭제된 객체는 회수하는 방식.



## 주요 용어 정리

- 객체 불변성 (Object Immutability): 객체 저장소에 저장된 데이터는 한 번 기록되면 수정이 불가능하며, 갱신하려면 새 버전의 객체를 생성해야 한다.
- 아이노드 (Inode): UNIX 파일 시스템에서 파일의 이름이 아닌 파일의 메타데이터와 디스크 위치 정보를 담고 있는 자료 구조.
- 안정 해시 (Consistent Hashing): 노드 수가 변해도 데이터 재분배를 최소화하여 분산 시스템의 확장성을 높이는 해싱 기법.
- 소거 코드 (Erasure Coding): 데이터를 분할하고 패리티 블록을 추가하여 저장 공간 오버헤드를 낮추면서 높은 내구성을 달성하는 데이터 중복성 기법.
- 멀티파트 업로드 (Multipart Upload): 대용량 파일을 작은 조각들로 나누어 병렬적으로 업로드한 후 서버에서 조립하여 효율성과 신뢰성을 높이는 방식.
- 쓰레기 수집 (Garbage Collection): 더 이상 사용되지 않는 객체가 차지하는 저장 공간을 주기적인 정리(Compaction) 과정을 통해 회수하는 절차.