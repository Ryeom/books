### 1. 직면한 문제와 시스템 목표

시스템 설계가 직면했던 핵심 문제는 대규모 인프라에서 발생하는 데이터의 압도적인 양과 특성이었다.

- 문제 1: 대규모 쓰기 부하: 일간 천만 개 수준의 지표가 발생하여 시스템은 쓰기 집약적(Write-Heavy) 특성을 갖는다. 이 데이터를 안정적으로, 그리고 손실 없이 처리하는 것이 최우선 과제.
- 문제 2: 비효율적인 데이터 저장: 지표 데이터는 시계열 데이터(Time-Series Data)라는 특수한 형태였다. 범용 관계형 데이터베이스(RDB)나 일반적인 NoSQL을 사용하면 데이터 압축, 집계, 장기 보관 요구사항(1년)을 충족하기 어렵고, 쿼리 지연 시간이 길어지는 문제가 있음.
- 문제 3: 안정성 확보 및 지연 시간: 데이터베이스 장애 발생 시 경보를 놓칠 수 있고, 대시보드나 경보 시스템이 지표를 조회할 때 응답 지연이 길면 운영 대응 능력이 저하.

시스템의 궁극적인 목표는 이러한 문제를 해결하여 높은 규모 확장성과 낮은 전송 지연, 그리고 중요 경보를 놓치지 않는 안정성을 확보하는 것이었다.

---

### 2. 핵심 해결책: 최적화된 데이터 파이프라인 구조 제시

문제 해결을 위해 지표 수집 → 전송 → 저장 → 분석/경보의 4단계로 구성된 고도로 분산된 파이프라인 구조를 제시.

#### 핵심 해결책 A: 데이터 저장소 최적화 (문제 2 해결)

- 해결책: 범용 데이터베이스 대신 시계열 데이터베이스(TSDB)를 채택했다 (예: InfluxDB, Prometheus).
- 원리: TSDB는 시계열 데이터의 특성에 맞춰 압축 및 인코딩(예: 이중-델타 인코딩)을 통해 저장 공간을 획기적으로 절감한다. 또한, 레이블 기반의 인덱싱으로 집계 쿼리 성능을 극대화하여 낮은 지연 시간으로 데이터를 분석할 수 있게 했다.
    

#### 핵심 해결책 B: 전송 안정성 및 규모 확장 (문제 1, 3 해결)

- 해결책: 지표 수집기와 데이터베이스 사이에 분산 메시지 큐(Kafka)를 도입.
- 원리:
    1. 쓰기 부하 완화: 수집된 데이터를 Kafka의 파티션으로 분산시켜 수집 부하를 분산 처리했다.
    2. 안정성 확보: Kafka는 데이터베이스에 장애가 발생하더라도 지표 데이터를 안전하게 보관(지속성)했다가, 시스템 복구 후 소비자가 다시 읽어갈 수 있도록 하여 데이터 손실을 완벽하게 방지했다. 이는 경보의 안정성에 필수적이었다.

#### 핵심 해결책 C: 데이터 보관 기간 관리

- 해결책: 다운샘플링(Downsampling) 기법을 적용했다.
- 원리: 사용자가 요청한 1년 보관 기간 동안 모든 데이터를 원본 해상도로 유지할 수 없었다. 따라서 데이터 보관 기간에 따라 해상도를 낮췄다. (예: 7일간 원본 보관, 7일 이후 30일간 1분 단위로 집계, 이후 1년간 1시간 단위로 집계). 이로써 장기 보관 요구사항을 충족시키면서 저장소 비용을 최소화했다.

---

### 3. 경보 및 운영 시스템 (가시화)

최종적으로 데이터를 활용하는 경보(Alerting) 및 시각화(Visualization) 시스템은 다음과 같이 구성했다.

- 지표 수집 모델: 풀(Pull) 모델 또는 푸시(Push) 모델 중 상황에 맞는 방식을 선택하도록 했고, 수집기 클러스터의 중복 문제를 해결하기 위해 안정 해시 링을 사용하여 서버당 수집 부하를 고르게 분산시켰다.
- 경보 시스템의 논리적 구성: 경보 관리자(Alert Manager)를 중심으로 구축되었다. 이 관리자는 설정된 규칙에 따라 주기적으로 TSDB에 쿼리를 실행하여 임계값 위반을 감지한다. 중요한 기능은 유사한 경보를 병합(Merge)하고 중복을 제거(Dedupe)하여 엔지니어의 경고 피로도(Alert Fatigue)를 낮추는 것이었다.
- 시스템 가시화: 그라파나(Grafana)와 같은 상용 시각화 도구를 도입하여 엔지니어에게 지표 추이, 패턴, 장애 지점을 즉각적으로 파악할 수 있는 대시보드를 제공했다.

---

## 주요 용어 정리

- 시계열 데이터 (Time-Series Data, TSDB): 타임스탬프와 함께 기록되는 값의 집합이다. 시간의 흐름에 따라 측정된 데이터의 패턴 분석에 최적화된 자료형임.
- 다운샘플링 (Downsampling): 데이터의 해상도를 낮추는 작업이다. 예를 들어 10초 단위 데이터를 1분 단위 데이터의 평균값으로 집계하여 저장 용량을 절감하는 기법임.
- 풀 모델 (Pull Model): 지표 수집기가 모니터링 대상 서버에 접속하여 데이터를 능동적으로 가져오는 방식이다. (예: Prometheus)
- 푸시 모델 (Push Model): 모니터링 대상 서버에 설치된 에이전트가 지표 수집기로 데이터를 수동적으로 보내는 방식이다. (예: CloudWatch)
- 카프카 (Kafka): 분산 스트리밍 플랫폼이다. 데이터 생산자(수집기)와 소비자(스트림 프로세서) 사이에서 대용량 데이터를 안정적이고 확장성 있게 전송 및 보관하는 역할을 수행함.
- 경보 관리자 (Alert Manager): 경보 규칙에 따라 질의 서비스를 호출하여 경보 이벤트를 생성하고, 중복되는 경보를 병합 및 필터링하여 사용자에게 알림을 전달하는 시스템 컴포넌트임.
- 레이블 (Label): 지표 데이터에 붙는 `<키:값>` 쌍의 메타데이터이다. 지표 데이터를 필터링하고 집계하는 데 사용되는 핵심 수단임.